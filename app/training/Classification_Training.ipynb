{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification_Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdnV1DtgiJws"
      },
      "source": [
        "**NOTE:**\r\n",
        "\r\n",
        "Before running the codes, you need to download the main project folder to the main directory of your Google Drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DijHRxEYPAzA"
      },
      "source": [
        "# Libraries and Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjBWbEGcPDsU"
      },
      "source": [
        "Import the necessary libraries and the TensorBoard notebook extension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV2LmzF1OKU5"
      },
      "source": [
        "%reset -f\r\n",
        "import keras\r\n",
        "import tensorflow as tf\r\n",
        "from keras import layers\r\n",
        "from keras.datasets import mnist\r\n",
        "import numpy as np\r\n",
        "from numpy import genfromtxt\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import matplotlib.image as mpimg \r\n",
        "from keras.callbacks import TensorBoard\r\n",
        "from google.colab import files\r\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\r\n",
        "from keras.models import Model, load_model\r\n",
        "from keras.preprocessing import image\r\n",
        "from keras.utils import layer_utils\r\n",
        "from keras.utils.data_utils import get_file\r\n",
        "from keras.applications.imagenet_utils import preprocess_input\r\n",
        "import pydot\r\n",
        "from IPython.display import SVG\r\n",
        "from keras.utils.vis_utils import model_to_dot\r\n",
        "from keras.utils import plot_model\r\n",
        "from keras.initializers import glorot_uniform\r\n",
        "import scipy.misc\r\n",
        "from matplotlib.pyplot import imshow\r\n",
        "import keras.backend as K\r\n",
        "from IPython.display import clear_output \r\n",
        "%matplotlib inline\r\n",
        "%reload_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5RJFlQbiPt-"
      },
      "source": [
        "Load the MNIST data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpceFCOtPLUe"
      },
      "source": [
        "num_classes = 10\r\n",
        "input_shape = (28, 28, 1)\r\n",
        "\r\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n",
        "\r\n",
        "x_train = x_train.astype(\"float32\") / 255\r\n",
        "x_test = x_test.astype(\"float32\") / 255\r\n",
        "\r\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\r\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWwx-scaiTm4"
      },
      "source": [
        "Add random noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pZENL2OEw8i"
      },
      "source": [
        "x_train_noisy = np.empty([len(x_train),28,28])\r\n",
        "\r\n",
        "for i in range(len(x_train)):\r\n",
        "  noise_factor = np.random.randint(0, 30)/100\r\n",
        "  x_train_noisy[i] = x_train[i] + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train[0].shape)\r\n",
        "\r\n",
        "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\r\n",
        "\r\n",
        "x_train = np.concatenate([x_train, x_train_noisy])\r\n",
        "y_train = np.concatenate([y_train, y_train])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cMmt85FPz4E"
      },
      "source": [
        "###Identity Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxgkuJSoPyDx"
      },
      "source": [
        "def identity_block(X, f, filters, stage, block):\r\n",
        "    # defining name basis\r\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\r\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\r\n",
        "    \r\n",
        "    F1, F2 = filters\r\n",
        "    \r\n",
        "    X_shortcut = X\r\n",
        "    \r\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\r\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\r\n",
        "    X = Activation('relu')(X)\r\n",
        "        \r\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\r\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\r\n",
        "\r\n",
        "    X = Add()([X_shortcut,X])\r\n",
        "    X = Activation('relu')(X)\r\n",
        "    \r\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZFyWVgiQN28"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):  \r\n",
        "    # defining name basis\r\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\r\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\r\n",
        "    \r\n",
        "    # Retrieve Filters\r\n",
        "    F1, F2 = filters\r\n",
        "    \r\n",
        "    X_shortcut = X\r\n",
        "\r\n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\r\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\r\n",
        "    X = Activation('relu')(X)\r\n",
        "    \r\n",
        "    X = Conv2D(filters = F2, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\r\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\r\n",
        "\r\n",
        "    X_shortcut = Conv2D(filters = F2, kernel_size = (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '1', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\r\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\r\n",
        "\r\n",
        "    X = Add()([X_shortcut,X])\r\n",
        "    X = Activation('relu')(X)\r\n",
        "    \r\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma_5YYT-QapL"
      },
      "source": [
        "def ResNet(input_shape, classes):   \r\n",
        "    # Define the input as a tensor with shape input_shape\r\n",
        "    X_input = Input(input_shape)\r\n",
        "\r\n",
        "    # Zero-Padding\r\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\r\n",
        "    \r\n",
        "    # Stage 1\r\n",
        "    X = Conv2D(32, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\r\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\r\n",
        "    X = Activation('relu')(X)\r\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\r\n",
        "\r\n",
        "    # Stage 2\r\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32], stage = 2, block='a', s = 1)\r\n",
        "    X = identity_block(X, 3, [32, 32], stage=2, block='b')\r\n",
        "\r\n",
        "    # Stage 3\r\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32], stage = 3, block='a', s = 2)\r\n",
        "    X = identity_block(X, 3, [32, 32], stage=3, block='b')\r\n",
        "    \r\n",
        "    # Stage 4\r\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32], stage = 4, block='a', s = 2)\r\n",
        "    X = identity_block(X, 3, [32, 32], stage=4, block='b')\r\n",
        "\r\n",
        "\r\n",
        "    # Stage 5\r\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32], stage = 5, block='a', s = 2)\r\n",
        "    X = identity_block(X, 3, [32, 32], stage=5, block='b')\r\n",
        "    \r\n",
        "    # AVGPOOL (â‰ˆ1 line). Use \"X = AveragePooling2D(...)(X)\"\r\n",
        "    # X = AveragePooling2D(pool_size=(2,2), name='avg_pool')(X)\r\n",
        "    \r\n",
        "    # output layer\r\n",
        "    X = Flatten()(X)\r\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\r\n",
        "    \r\n",
        "    # Create model\r\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\r\n",
        "    model.summary()\r\n",
        "\r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOeSxvR4ics2"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP00NbB1Qn_a"
      },
      "source": [
        "model = ResNet(input_shape = input_shape, classes = num_classes)\r\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "model.fit(x_train, y_train, epochs = 2, batch_size = 32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF2DkjU_imK0"
      },
      "source": [
        "# Testing the ResNet classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYPULK2YiqKd"
      },
      "source": [
        "We use 1000 MNIS test images to calculate the accuracy. First, load the trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM4Z5SVAdDQ2"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "\r\n",
        "model = load_model('/content/drive/MyDrive/KABAS-OGUTEN-EE3001-Term-Project/models/classification.h5') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wA6AyJ9CjcRG"
      },
      "source": [
        "Calculate accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMA_tWVIc4JS",
        "outputId": "62f9e248-e527-498f-d333-622b8517f154"
      },
      "source": [
        "length = 1000\r\n",
        "correct = 0\r\n",
        "for i in range(length):\r\n",
        "  img = x_test[i]\r\n",
        "  img = np.reshape(img, (1, 28, 28, 1))\r\n",
        "  pre = model.predict(img)\r\n",
        "  if np.argmax(pre) == np.argmax(y_test[i]):\r\n",
        "    correct = correct + 1\r\n",
        "  clear_output()\r\n",
        "  print(i, \"/\", length)\r\n",
        "\r\n",
        "print(\"Accuracy: \" + str(correct*100/length) + \"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "999 / 1000\n",
            "Accuracy: 98.9%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}